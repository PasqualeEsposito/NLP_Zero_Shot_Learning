{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQuHkfWy-qYX"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw1o-04zAFLM"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!pip install xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb_E2OwrWCd_"
      },
      "source": [
        "## Upload datasets and utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N1li5ZNZVySu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqvqzh87V35_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okLoDQHyV7ei"
      },
      "outputs": [],
      "source": [
        "path_prefix = \"/content/gdrive/MyDrive/DATASETS/QA/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av32hjNEV9o9"
      },
      "outputs": [],
      "source": [
        "cd /content/gdrive/MyDrive/DATASETS/QA/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgdB6Ni1WE-K"
      },
      "outputs": [],
      "source": [
        "QA_DATASETS = [\n",
        "     {\n",
        "        \"name\": \"quarel\", #ok\n",
        "        \"sep\": False,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": False,\n",
        "        \"num_options\": 2,\n",
        "        \"FLAN\": [2, 4, 13],\n",
        "        \"GPT2\": [3, 10, 11],\n",
        "        \"BART\": [6, 9, 10]\n",
        "    }, {\n",
        "        \"name\": \"quartz-no_knowledge\", #ok\n",
        "        \"sep\": False,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": False,\n",
        "        \"num_options\": 2,\n",
        "        \"FLAN\": [1, 6, 13],\n",
        "        \"GPT2\": [1, 5, 10],\n",
        "        \"BART\": [2, 3, 6]\n",
        "    },{\n",
        "        \"name\": \"quartz-with_knowledge\", #ok\n",
        "        \"sep\": False,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": False,\n",
        "        \"num_options\": 2,\n",
        "        \"FLAN\": [1, 2, 5],\n",
        "        \"GPT2\": [7, 10, 14],\n",
        "        \"BART\": [11, 13, 14]\n",
        "    },\n",
        "     {\n",
        "        \"name\": \"race-middle\", #ok\n",
        "        \"sep\": True,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": True,\n",
        "        \"num_options\": 4,\n",
        "        \"FLAN\": [3, 6, 7],\n",
        "        \"GPT2\": [5, 10, 13],\n",
        "        \"BART\": [7, 10, 11]\n",
        "    }, {\n",
        "        \"name\": \"sciq\", #ok\n",
        "        \"sep\": True,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": True,\n",
        "        \"num_options\": 4,\n",
        "        \"FLAN\": [2, 6, 8],\n",
        "        \"GPT2\": [5, 8, 14],\n",
        "        \"BART\": [9, 12, 14]\n",
        "    }, {\n",
        "        \"name\": \"social_i_qa\", #ok\n",
        "        \"sep\": True,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": True,\n",
        "        \"num_options\": 3,\n",
        "        \"FLAN\": [1, 4, 8],\n",
        "        \"GPT2\": [1, 4, 14],\n",
        "        \"BART\": [0, 2, 4]\n",
        "    }, {\n",
        "        \"name\": \"superglue-copa\", #ok\n",
        "        \"sep\": False,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": False,\n",
        "        \"num_options\": 2,\n",
        "        \"FLAN\": [2, 5, 8],\n",
        "        \"GPT2\": [7, 10, 12],\n",
        "        \"BART\": [0, 1, 4]\n",
        "    },\n",
        "     {\n",
        "        \"name\": \"wino_grande\", #ok\n",
        "        \"sep\": False,\n",
        "        \"initial_premise\": False,\n",
        "        \"end_premise\": False,\n",
        "        \"num_options\": 2,\n",
        "        \"FLAN\": [1, 10, 11],\n",
        "        \"GPT2\": [9, 11, 13],\n",
        "        \"BART\": [5, 9, 12]\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr4egMbYWSZa"
      },
      "outputs": [],
      "source": [
        "QA_PROMPTS = [\n",
        "    \"Question: {QUESTION}\\nOptions: {OPTIONS}\\nDo not give an explanation to the answer you give\\n\",\n",
        "    \"For the following Question Answering task choose the correct answer between the given options. Question: {QUESTION}. Options: {OPTIONS}\",\n",
        "    \"Given the following Question Answering task, choose an answer between the options. Question: {QUESTION}. Options: {OPTIONS}\",\n",
        "    \"Give an answer for the following Question Answering task. Question: {QUESTION}. Options: {OPTIONS}\",\n",
        "    \"Which is the correct answer among the options? Question: {QUESTION}. Options: {OPTIONS}\",\n",
        "    \"Choose the correct answer among the options. Question: {QUESTION}. Options: {OPTIONS}\",\n",
        "    \"Given these options {OPTIONS}, answer the following question: {QUESTION}. Answer using only the words present in the options.\",\n",
        "    \"Answer the following question:\\n\\n{QUESTION}\\n\\nOptions: {OPTIONS}\",\n",
        "    \"Answer this question:\\n\\n{QUESTION}?\\nOptions: {OPTIONS}\",\n",
        "    \"What is the answer to this question? {QUESTION}\\nOptions: {OPTIONS}\",\n",
        "    \"What is the answer to the following: {QUESTION}? {OPTIONS}\",\n",
        "    \"Provide the answer to: {QUESTION}. {OPTIONS}\",\n",
        "    \"Answer the following: {QUESTION}. {OPTIONS}\",\n",
        "    \"What is the response to: {QUESTION}? {OPTIONS}\",\n",
        "    \"In the following text: {QUESTION}, what is the answer? {OPTIONS}\",\n",
        "    \"Given the input {QUESTION}, provide the answer. {OPTIONS}\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJo3HmFIWYu0"
      },
      "outputs": [],
      "source": [
        "def handle_initial_sep(query, separator = \"\\[SEP\\]\"):\n",
        "  qpa = re.split(separator, query) #Vector containing in this order QUESTION, PREMISE and ANSWER.\n",
        "  return f\"{qpa[1]}{qpa[0]}{qpa[2]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77tPfWU9WboK"
      },
      "outputs": [],
      "source": [
        "def handle_end_sep(query, separator = \"\\[SEP\\]\", to_remove=[]):\n",
        "  if (len(to_remove) != 0):\n",
        "    for substr in to_remove:\n",
        "      query = query.replace(substr, '')\n",
        "\n",
        "  qap = re.split(separator, query)\n",
        "\n",
        "  return f\"{qap[1]}{qap[0]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiglJ4QVWVpF"
      },
      "outputs": [],
      "source": [
        "def import_dataset(dataset_index):\n",
        "  dataset_info = QA_DATASETS[dataset_index];\n",
        "\n",
        "  dataset_name = dataset_info[\"name\"]\n",
        "  print(dataset_name)\n",
        "  #for seed in DATASET_SEEDS:\n",
        "  seed = 100 #test_set is equal independently on random seed\n",
        "  test_set_path = f\"{dataset_name}/{dataset_name}_32_{seed}_test.tsv\"\n",
        "  #print(test_set_path)\n",
        "  df = pd.read_csv(test_set_path , sep=\"\\t\", header=None)\n",
        "\n",
        "  has_sep = dataset_info[\"sep\"]\n",
        "  has_initial_premise = dataset_info[\"initial_premise\"]\n",
        "  has_end_premise = dataset_info[\"end_premise\"]\n",
        "\n",
        "  if(has_sep and has_initial_premise):\n",
        "    df[0] = df[0].map(handle_initial_sep)\n",
        "\n",
        "  if(has_sep and has_end_premise):\n",
        "    if(has_sep != True):\n",
        "      df[0] = df[0].apply(lambda q: handle_end_sep(q, has_sep, [\"question:\"]))\n",
        "    else:\n",
        "      df[0] = df[0].map(handle_end_sep)\n",
        "  #print(df[0][6])\n",
        "  return (df[0], df[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPnkWLCPWZV_"
      },
      "outputs": [],
      "source": [
        "for dataset_index in range (0, len(QA_DATASETS)):\n",
        "  import_dataset(dataset_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw7GcMW6WlYY"
      },
      "outputs": [],
      "source": [
        "def adapt_prompt(prompt_index, question, options):\n",
        "  return QA_PROMPTS[prompt_index].format(QUESTION = question, OPTIONS = options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12JDvAW4W8Hw"
      },
      "outputs": [],
      "source": [
        "def preprocess(premises):\n",
        "  premises.tolist()\n",
        "  question = []\n",
        "  answer = []\n",
        "\n",
        "  for premise in premises:\n",
        "    split = re.split(\"\\([A-H]\\)\", premise)\n",
        "    question.append(split.pop(0))\n",
        "    answer.append(split)\n",
        "\n",
        "  return question, answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt6uOWYLWFnH"
      },
      "source": [
        "## Upload model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ixV3pAH_8Dn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naqKBImF_nqx"
      },
      "outputs": [],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"zero-shot-classification\", model=\"niting3c/llama-2-7b-hf-zero-shot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP7DQz6yMCXe"
      },
      "outputs": [],
      "source": [
        "sequences = pipeline(\n",
        "    \"Answer the following QA question printing only the correct option (no need of explanation):\\nQUESTION: Tommy glided across the marble floor with ease, but slipped and fell on the wet floor because _____ has more resistance. OPTIONS: [' marble floor ', ' wet floor']\\n\",\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_length=200,\n",
        ")\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y_Sgd1nY-HH"
      },
      "outputs": [],
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feANh9mMY-A7"
      },
      "outputs": [],
      "source": [
        "sequences[0][0]['generated_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0R1ikZHZWV_"
      },
      "outputs": [],
      "source": [
        "sequences[1][0]['generated_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIqaUO5hZWSR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfleWXY9ZWPM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsX4bfeaQahz"
      },
      "outputs": [],
      "source": [
        "match = re.search(\"(Correct answer: \\([A-D]\\)).*\", seq['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvdVb6OaQxpl"
      },
      "outputs": [],
      "source": [
        "match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5np6zNhQybp"
      },
      "outputs": [],
      "source": [
        "match = re.sub(\"(Correct answer: \\([A-D]\\)).\", \"\", match.group(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmgDgQUgR6A5"
      },
      "outputs": [],
      "source": [
        "match.replace('.', '').replace(' ', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD9h0qd4maEt"
      },
      "outputs": [],
      "source": [
        "sequences = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy07nCYiR6yh"
      },
      "outputs": [],
      "source": [
        "def askLlama2QA(data, solutions, prompt_index = None):\n",
        "  q, a = preprocess(data)\n",
        "  results = []\n",
        "  prompt = []\n",
        "  solutions = solutions.tolist()\n",
        "\n",
        "  for question, options, solution in zip(q, a, solutions):\n",
        "    if(prompt_index != None):\n",
        "      prompt = adapt_prompt(prompt_index, question, options)\n",
        "    else:\n",
        "      prompt = question\n",
        "\n",
        "    sequence = pipeline(\n",
        "      prompt,\n",
        "      do_sample=True,\n",
        "      top_k=10,\n",
        "      num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      max_length=200\n",
        "    )\n",
        "\n",
        "    print(sequence[0]['generated_text'], \"\\n\\n\\n\")\n",
        "\n",
        "    #print(flan_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[0].replace(\" \", \"\").replace(\".\", \"\").lower())\n",
        "    #print(solution.replace(\" \", \"\").replace(\".\", \"\").lower())\n",
        "\n",
        "    #print(f\"FLAN answer: {result}, correct answer: {solution}\")\n",
        "\n",
        "    #for i in range (0, len(q)):\n",
        "    #  print(\"Question \", i+1, \": \", sequences[i][0]['generated_text'])\n",
        "      #print(re.search(\"(Correct answer: \\([A-D]\\)).*\", sequences[i][0]['generated_text']))\n",
        "      #print(re.search(\"(Correct answer: \\([A-D]\\)).*\", sequences[i][0]['generated_text']), \", \", solution, \": \", re.search(\"(Correct answer: \\([A-D]\\)).*\", sequences[i][0]['generated_text']).contains(solution))\n",
        "      #if(re.search(\"(Correct answer: \\([A-D]\\)).*\", sequences[i][0]['generated_text']).contains(solution)):\n",
        "      #  results.append(True)\n",
        "      #else:\n",
        "      #  results.append(False)\n",
        "\n",
        "\n",
        "    #results.append(flan_tokenizer.batch_decode(output_sequences, skip_special_tokens=True))\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61W3OxrVbUvi"
      },
      "outputs": [],
      "source": [
        "def final_tests():\n",
        "    for dataset_index in range (0, len(QA_DATASETS)):\n",
        "      for prompt in range (0, 1):\n",
        "        question, answer = import_dataset(dataset_index)\n",
        "        results = askLlama2QA(question[0:5], answer[0:5], prompt)\n",
        "\n",
        "        dataset_name = QA_DATASETS[dataset_index][\"name\"]\n",
        "\n",
        "        #corrects = sum(bool(x) for x in results)\n",
        "\n",
        "        #str = f\"Model: {model}\\tDataset name: {dataset_name}\\tPrompt index: {prompt} - Correct Answers {corrects}/{len(results)} - {corrects/len(results)}\"\n",
        "        #print(str)\n",
        "        corrects = 0\n",
        "      print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUknYJImbm8O"
      },
      "outputs": [],
      "source": [
        "final_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3au1lJxb63m"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"sciq/sciq_32_100_test.tsv\", sep=\"\\t\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj6k2nxW9Dlf"
      },
      "outputs": [],
      "source": [
        "sequence = pipeline(\n",
        "      df[0].tolist(),\n",
        "      do_sample=True,\n",
        "      top_k=10,\n",
        "      num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      max_length=800\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaMOMVMSKXtn"
      },
      "outputs": [],
      "source": [
        "sequence[0][0]['generated_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoeEw_kUKNq6"
      },
      "outputs": [],
      "source": [
        "content = ''\n",
        "for item in sequence:\n",
        "  content += item[0]['generated_text'] + \"\\n\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5ihJc5AK0PJ"
      },
      "outputs": [],
      "source": [
        "content = content.encode('ascii', 'ignore').decode('ascii')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh8ooyw_JqV9"
      },
      "outputs": [],
      "source": [
        "f = open(\"/content/gdrive/MyDrive/sciq-result\", \"a\")\n",
        "f.write(content)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWUy1AW15Y_9"
      },
      "source": [
        "## TIME COMPUTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4XHCWG9mhwE"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r3b2pzO5soo"
      },
      "outputs": [],
      "source": [
        "def time_tests():\n",
        "  for dataset_index in range (0, len(QA_DATASETS)):\n",
        "      for prompt in range (0, 1):\n",
        "        question, answer = import_dataset(dataset_index)\n",
        "        start = time.time()\n",
        "        results = askLlama2QA(question[0:32], answer[0:32], prompt)\n",
        "        end = time.time()\n",
        "\n",
        "        dataset_name = QA_DATASETS[dataset_index][\"name\"]\n",
        "\n",
        "        print(f\"{dataset_name} time: {end-start}\")\n",
        "      print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyqeetVg5upP"
      },
      "outputs": [],
      "source": [
        "time_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWYCmHX-26OR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn2pcukK6ece"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"quarel/quarel_32_100_test.tsv\", sep=\"\\t\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAnV65pI24ul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTqc6M5/8WIPJmRYm3Uiy1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}